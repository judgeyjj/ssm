"""
FASS-MoE æ¨¡å‹å¥åº·æ£€æŸ¥è„šæœ¬

ä¸¥æ ¼éªŒè¯:
1. Forward Pass - ä¸Šé‡‡æ ·å€ç‡å’Œè¾“å‡ºèŒƒå›´
2. Streaming Pass - ä¸ Forward çš„ç²¾ç¡®ä¸€è‡´æ€§ (å­¦æœ¯çº§è¦æ±‚)
3. æ¢¯åº¦æ£€æŸ¥ - åå‘ä¼ æ’­
"""

import torch
import numpy as np
from config import get_default_config
from generator import build_generator

def set_seed(seed=42):
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
    np.random.seed(seed)

def check_model():
    print("\n" + "="*60)
    print("ğŸ§ª FASS-MoE æ¨¡å‹å¥åº·æ£€æŸ¥ (å­¦æœ¯çº§ä¸¥æ ¼éªŒè¯)")
    print("="*60)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device}")
    
    # åˆå§‹åŒ–
    config = get_default_config()
    config.model.hidden_channels = 32
    config.model.num_moe_layers = 2
    
    model = build_generator(config).to(device)
    model.eval()
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ | å‚æ•°é‡: {total_params/1e6:.2f}M")

    # æ¨¡æ‹Ÿæ•°æ®
    B, C, L = 2, 1, 16000
    set_seed(42)  # å›ºå®šç§å­
    x = torch.randn(B, C, L).to(device)
    
    # ============================================================
    # [Step 1] Forward Pass
    # ============================================================
    print("\n" + "-"*40)
    print("[Step 1] æ ‡å‡† Forward Pass")
    print("-"*40)
    
    with torch.no_grad():
        y_forward, aux_loss = model(x)
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {y_forward.shape}")
    print(f"Aux Loss: {aux_loss.item():.4f}")
    
    # æ£€æŸ¥ä¸Šé‡‡æ ·
    target_len = L * 3
    assert y_forward.shape[-1] == target_len, f"é•¿åº¦é”™è¯¯: {y_forward.shape[-1]} != {target_len}"
    print(f"âœ… è¾“å‡ºé•¿åº¦æ­£ç¡®: {target_len}")

    # æ£€æŸ¥è¾“å‡ºèŒƒå›´
    min_val, max_val = y_forward.min().item(), y_forward.max().item()
    assert -1.01 <= min_val <= max_val <= 1.01, f"èŒƒå›´å¼‚å¸¸: [{min_val}, {max_val}]"
    print(f"âœ… è¾“å‡ºèŒƒå›´æ­£ç¡®: [{min_val:.4f}, {max_val:.4f}]")

    # ============================================================
    # [Step 2] Streaming Pass - ç²¾ç¡®ä¸€è‡´æ€§éªŒè¯
    # ============================================================
    print("\n" + "-"*40)
    print("[Step 2] Streaming ç²¾ç¡®ä¸€è‡´æ€§éªŒè¯")
    print("-"*40)
    
    # æµ‹è¯•ä¸åŒçš„ chunk å¤§å°
    chunk_sizes = [800, 1600, 3200]  # 50ms, 100ms, 200ms @ 16kHz
    
    for chunk_size in chunk_sizes:
        if L % chunk_size != 0:
            continue
            
        total_chunks = L // chunk_size
        
        state = None
        output_chunks = []
        
        with torch.no_grad():
            for i in range(total_chunks):
                chunk = x[:, :, i*chunk_size : (i+1)*chunk_size]
                out_chunk, state = model.infer_stream(chunk, state)
                output_chunks.append(out_chunk)
        
        y_stream = torch.cat(output_chunks, dim=-1)
        
        # è®¡ç®—è¯¯å·®
        diff = torch.abs(y_forward - y_stream)
        max_diff = diff.max().item()
        mean_diff = diff.mean().item()
        
        # ç›¸å¯¹è¯¯å·®
        rel_diff = (diff / (torch.abs(y_forward) + 1e-8)).mean().item()
        
        status = "âœ…" if max_diff < 1e-5 else ("âš ï¸" if max_diff < 1e-3 else "âŒ")
        
        print(f"\nChunk={chunk_size} ({chunk_size/16:.0f}ms, {total_chunks} chunks):")
        print(f"  æœ€å¤§ç»å¯¹è¯¯å·®: {max_diff:.2e}")
        print(f"  å¹³å‡ç»å¯¹è¯¯å·®: {mean_diff:.2e}")
        print(f"  å¹³å‡ç›¸å¯¹è¯¯å·®: {rel_diff:.2e}")
        print(f"  {status} ä¸€è‡´æ€§: {'ç²¾ç¡®ä¸€è‡´' if max_diff < 1e-5 else ('å¯æ¥å—' if max_diff < 1e-3 else 'ä¸ä¸€è‡´!')}")

    # ============================================================
    # [Step 3] æ¢¯åº¦æ£€æŸ¥
    # ============================================================
    print("\n" + "-"*40)
    print("[Step 3] æ¢¯åº¦æ£€æŸ¥")
    print("-"*40)
    
    model.train()
    x_grad = torch.randn(B, C, L, device=device, requires_grad=True)
    y_train, aux_loss = model(x_grad)
    loss = y_train.mean() + 0.01 * aux_loss
    loss.backward()
    
    total_params = sum(1 for p in model.parameters())
    params_with_grad = sum(1 for p in model.parameters() if p.grad is not None)
    
    print(f"âœ… åå‘ä¼ æ’­æˆåŠŸ")
    print(f"   {params_with_grad}/{total_params} å‚æ•°æœ‰æ¢¯åº¦")

    # ============================================================
    # [Step 4] è¾¹ç•Œæ¡ä»¶æ£€æŸ¥
    # ============================================================
    print("\n" + "-"*40)
    print("[Step 4] è¾¹ç•Œæ¡ä»¶")
    print("-"*40)
    
    model.eval()
    test_lengths = [1600, 8000, 16000, 32000]
    
    with torch.no_grad():
        for length in test_lengths:
            x_test = torch.randn(1, 1, length, device=device)
            y_test, _ = model(x_test)
            expected = length * 3
            status = "âœ…" if y_test.shape[-1] == expected else "âŒ"
            print(f"{status} è¾“å…¥ {length:>5} â†’ è¾“å‡º {y_test.shape[-1]:>6} (æœŸæœ› {expected})")

    print("\n" + "="*60)
    print("ğŸ‰ å¥åº·æ£€æŸ¥å®Œæˆ!")
    print("="*60)


if __name__ == "__main__":
    check_model()
